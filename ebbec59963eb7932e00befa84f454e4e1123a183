{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "823c2e69_9aeead69",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 8
      },
      "lineNbr": 0,
      "author": {
        "id": 1000030
      },
      "writtenOn": "2022-04-04T05:35:25Z",
      "side": 1,
      "message": "This is PoC implementation to optimize `gn gen`.\n\nIf this direction is acceptable for gn, I\u0027ll split this CL to\n1. WaitGroup introduction\n2. Parallelize ResolveItem\n\nI\u0027m also wondering how you feel about introducing absl to GN for\nhttps://cs.opensource.google/abseil/abseil-cpp/+/master:absl/base/thread_annotations.h and replace std::mutex with absl::Mutex where appropriate.",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "38d6e849_22331597",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 8
      },
      "lineNbr": 0,
      "author": {
        "id": 1000067
      },
      "writtenOn": "2022-04-04T08:55:20Z",
      "side": 1,
      "message": "A long time ago, I wrote a GN CL [1] to build and link TCMalloc, which depends on ABSL, my experience was that Absl is very hard to properly build without Bazel or CMake. It was so bad that I had to cherry-pick the Absl headers used by TCMalloc instead of trying to pull the whole library, and I had to manually patch a few of them. Also, it is a _very_ large dependency, and depends on GoogleTest itself.\n\nI suggest instead that if you want thread annotations, add them to a new header like $GN/src/base/threads/thread_annotations.h and use that directly.\n\n[1] https://gn-review.googlesource.com/c/gn/+/8020",
      "parentUuid": "823c2e69_9aeead69",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "41afc049_d258041d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 8
      },
      "lineNbr": 0,
      "author": {
        "id": 1000030
      },
      "writtenOn": "2022-04-06T07:05:02Z",
      "side": 1,
      "message": "I see, but I think having absl only is not so much difficult compared to introducing tcmalloc. Most of absl component will be usable by having include directory and listing cc files which we want to use in gen.py.",
      "parentUuid": "38d6e849_22331597",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9abfc763_52f5989b",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 74,
      "author": {
        "id": 1000067
      },
      "writtenOn": "2022-04-04T08:30:57Z",
      "side": 1,
      "message": "If I understand correctly, any worker thread could fail and overwrite |success_\\ and |err_| here, and only the result of the last one will be considered in Wait().\n\nIn other words, this makes error output non-deterministic when multiple resolved items would fail. From experience, that\u0027s is bound to make debugging some issues a real pain. Is there a way to collect all possible errors and re-order them in a deterministic way after the parallel resolution for consistent error reporting?",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a865d670_57d2bef9",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 74,
      "author": {
        "id": 1000030
      },
      "writtenOn": "2022-04-06T07:05:02Z",
      "side": 1,
      "message": "I think we need to implement comparator for Err and store that in vector with sort.",
      "parentUuid": "9abfc763_52f5989b",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3b070034_70cc9069",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 77,
      "author": {
        "id": 1000067
      },
      "writtenOn": "2022-04-04T08:30:57Z",
      "side": 1,
      "message": "nit: I believe it is slightly more efficient to send the notification after unlocking the mutex. See https://stackoverflow.com/questions/55154462/c-condition-variable-notify-one-before-or-after-release-lock\n\nI don\u0027t understand this code, first therre is the use of notify_one() here. It looks like several threads could be waiting on the same condition variables at the same time and would need to be woken up when workers reaches 0, so notify_all() would be needed instead. Am I missing something?\n\nSecond, why not only notify when the count reaches 0? it seems completely unnecessary to wake any waiting thread until this happens.",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a32f39ca_0afbbc21",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 77,
      "author": {
        "id": 1000067
      },
      "writtenOn": "2022-04-04T08:49:16Z",
      "side": 1,
      "message": "Oh, I see now that this class does not implement a real \"wait group\" because in practice only a single thread (the main one) calls Wait(), while worker threads can call Add() to launch additional tasks. Maybe name this calss differently then to avoid confusion.",
      "parentUuid": "3b070034_70cc9069",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e6ab3da8_3f5ba146",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 77,
      "author": {
        "id": 1000030
      },
      "writtenOn": "2022-04-06T07:05:02Z",
      "side": 1,
      "message": "Name of this class is somehow inspired by https://pkg.go.dev/sync#WaitGroup.\nBut suggestions are welcome if you have.",
      "parentUuid": "a32f39ca_0afbbc21",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "21804f50_e576870e",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 531,
      "author": {
        "id": 1000067
      },
      "writtenOn": "2022-04-04T08:49:16Z",
      "side": 1,
      "message": "ResolveDeps() and other functions here end up calling Builder::GetRecord() which access the Builder::records_ map without any kind of lock contention. I am surprised that this works reliably since Builder::ItemDefined() which updates the map can be called from multiple threads now, IIRC.\n\nAll this to say that I find the lack of clear separation of what is accessed from multiple threads, and what is expected to run in the main thread confusing, and a source of problems for future refactors. Also from my own benchmarking, most of the heavy duty that could be parallelized happens in Target::OnResolved() and consists in all the set merges from configs and dependency information.\n\nHow can we make these actions more parallelizable while keeping the code base understandable? One idea that I wished to experiment with was to separate most of the data computed in Target::OnResolved() into a separate class (e.g. ConfiguredTarget or something) that would allow parallel computations, making the original Target graph read-only, and faster to compute in a single thread, but I am open to suggestions.",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "159639f5_af12dee8",
        "filename": "src/gn/builder.cc",
        "patchSetId": 8
      },
      "lineNbr": 531,
      "author": {
        "id": 1000030
      },
      "writtenOn": "2022-04-06T07:05:02Z",
      "side": 1,
      "message": "\u003e ResolveDeps() and other functions here end up calling Builder::GetRecord() which access the Builder::records_ map without any kind of lock contention. I am surprised that this works reliably since Builder::ItemDefined() which updates the map can be called from multiple threads now, IIRC.\n\u003e \n\nI think Builder::ItemDefined() is only called from main thread in this implementation and concurrent read/write access to Builder::records_ doesn\u0027t happen?\n\n\u003e All this to say that I find the lack of clear separation of what is accessed from multiple threads, and what is expected to run in the main thread confusing, and a source of problems for future refactors. Also from my own benchmarking, most of the heavy duty that could be parallelized happens in Target::OnResolved() and consists in all the set merges from configs and dependency information.\n\u003e \n\nHmm, yeah. I agree this doesn\u0027t have clear separation. I think we can use DCHECK for thread to clarify which thread is used to run functions.\n\nAlso I\u0027m not sure whether we can parallelize Target::OnResovled() efficiently without parallelizing Builder::ResolveIteam().\n\n\u003e How can we make these actions more parallelizable while keeping the code base understandable? One idea that I wished to experiment with was to separate most of the data computed in Target::OnResolved() into a separate class (e.g. ConfiguredTarget or something) that would allow parallel computations, making the original Target graph read-only, and faster to compute in a single thread, but I am open to suggestions.\n\nI\u0027m not sure what you mean here. How do separate calsses allow parallel computation?",
      "parentUuid": "21804f50_e576870e",
      "revId": "ebbec59963eb7932e00befa84f454e4e1123a183",
      "serverId": "c360c8e5-7aa8-3905-a7a0-810934766dac"
    }
  ]
}